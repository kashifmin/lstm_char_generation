{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Activation, Dense\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = 'english.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ', 'e', 'q', 'u', 'x', 'f', 'w', 'j', 's', 'l', 'a', 'g', 'y', 'r', '.', 'h', '\\n', 'p', 'z', 'o', 't', 'd', 'k', 'n', 'c', 'b', 'm', 'v', 'i'} 29\n",
      "{0: ' ', 1: 'e', 2: 'q', 3: 'u', 4: 'x', 5: 'f', 6: 'w', 7: 'j', 8: 's', 9: 'l', 10: 'a', 11: 'g', 12: 'y', 13: 'r', 14: '.', 15: 'h', 16: '\\n', 17: 'p', 18: 'z', 19: 'o', 20: 't', 21: 'd', 22: 'k', 23: 'n', 24: 'c', 25: 'b', 26: 'm', 27: 'v', 28: 'i'}\n"
     ]
    }
   ],
   "source": [
    "f = open(dataset, 'r')\n",
    "data = f.read().strip()\n",
    "chars = set(data)\n",
    "print(chars, len(chars))\n",
    "index_to_char = dict([(i,e) for i, e in enumerate(chars)])\n",
    "char_to_index = dict([(e, i) for i, e in enumerate(chars)])\n",
    "print(index_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NCHARS = len(chars)\n",
    "MAXLEN_SENTENCE = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "# create a list of sentences and the next char after that sentence\n",
    "sentences = []\n",
    "nextchars = []\n",
    "\n",
    "for i in range(0, len(data)-MAXLEN_SENTENCE-1):\n",
    "    sentences.append(data[i:i+MAXLEN_SENTENCE])\n",
    "    nextchars.append(data[i + MAXLEN_SENTENCE])\n",
    "    \n",
    "    if(len(sentences) == 20000):\n",
    "        break\n",
    "NSENTENCES = len(sentences)\n",
    "print(len(sentences))\n",
    "print(len(sentences[77]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.zeros((NSENTENCES, MAXLEN_SENTENCE, NCHARS), dtype=np.bool)\n",
    "trainY = np.zeros((NSENTENCES, NCHARS), dtype=np.bool)\n",
    "\n",
    "for i in range(NSENTENCES):\n",
    "    for j, e in enumerate(sentences[i]):\n",
    "        trainX[i][j][char_to_index[e]] = 1\n",
    "    trainY[i][char_to_index[nextchars[i]]] = 1\n",
    "    \n",
    "np.save('trainX', trainX)\n",
    "np.save('trainY', trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_59 (LSTM)               (None, 70, 256)           292864    \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 70, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_60 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 29)                7453      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 29)                0         \n",
      "=================================================================\n",
      "Total params: 825,629\n",
      "Trainable params: 825,629\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape = trainX.shape[1:], return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(NCHARS))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n",
      "11200/14000 [=======================>......] - ETA: 10s - loss: 0.4330 - acc: 0.8701"
     ]
    }
   ],
   "source": [
    "model.fit(trainX, trainY, batch_size=64, validation_split=0.3, epochs=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "Seed:  he towering height of mount sinai saying hold firmly to what we have g\n",
      "--------------------------------------------------\n",
      "he towering height of mount sinai saying hold firmly to what we have given you and bring ever and earen and in to us ara fall things then he placed them what allah hath revealed to you that they are to meet their lord and that they are to meet their lord and that they are to meet their lord and that they are to meet their lord and that they are to \n"
     ]
    }
   ],
   "source": [
    "def predictNextChar(sampleText, start):\n",
    "#     print(sampleText)\n",
    "    x = np.zeros((1, MAXLEN_SENTENCE, NCHARS), dtype=bool)\n",
    "    for i, c in enumerate(sampleText[start:start+MAXLEN_SENTENCE]):\n",
    "        x[0][i][char_to_index[c]] = 1\n",
    "#     predicted = model.predict(x)\n",
    "#     print(np.argmax(predicted[0]))\n",
    "    y = index_to_char[np.argmax(model.predict(x)[0])]\n",
    "    return y\n",
    "    \n",
    "def generateText(seed):\n",
    "    result = str(seed)\n",
    "    print(len(seed))\n",
    "    print('Seed: ', seed)\n",
    "    print('-'*50)\n",
    "    i = 0\n",
    "    maxlen = 350\n",
    "    while len(result) < maxlen:\n",
    "        result += predictNextChar(result, i)\n",
    "        i += 1\n",
    "    return result\n",
    "print(generateText(sentences[16366]))\n",
    "# print(predictNextChar(sentences[2], 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
